{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "\n",
    "- **Ava Kam**- Background research, Visualization, Conceptualization, Project administration, Writing - original draft, Writing – review & editing<br>\n",
    "- **Amelia Lin**- Background research ,Visualization, Conceptualization, Project administration, Writing - original draft, Writing – review & editing<br>\n",
    "- **Neha Khalkho**- Background research, Experimental investigation, Writing – original draft, Writing – review & editing<br>\n",
    "- **Charlie Ngo**- Analysis, Background research, Data curation, Experimental investigation, Software, Writing – Review & editing<br>\n",
    "- **Ben Chen**- Analysis, Background research, Data curation, Experimental investigation, Software, Writing – Review & editing<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To what extent can county-level unemployment rates, per-capita personal income, and regional economic activity be used to predict drug overdose mortality rates in California counties from 2010–2019, and how far in advance do changes in these economic indicators signal future increases in overdose deaths?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drug abuse has been a prevalent societal issue plaguing the US society for the past decades, yet interestingly, different counties and regions seem to have significantly different drug abuse levels. There could be a plethora of reasons why a particular county or region experiences a drastic increase or decrease in drug abuse, among which include local economic landscape, healthcare service availability, education level,l and so on<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1).<br>\n",
    "\n",
    "Given that there is a high comorbidity between drug abuse and psychiatric disorder/mental health crisis<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2), and the fact that financial stressors and local economic landscape significantly impact the psychological distress<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3), we believe the economic landscape(unemployment rate and economic decline) could potentially predict drug abuse rate. These predictions could potentially help us better prepare regions from drug abuse and public health crises, during certain economic landscapes.<br>\n",
    "\n",
    "Like how we hypothesized, there do seem to be studies showing the potential relationship between economic recession/unemployment rate and drug usage<a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4). For instance 17 out of 28 studies in this literature review found this \"counter-cyclical mechanism\" where unempolyment increase and recession lead to increased drug use<a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4).\n",
    "\n",
    "\n",
    "***Reference***\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) National Institute on Drug Abuse. (2020, July 10). Understanding drug use and addiction drugfacts. https://nida.nih.gov/publications/drugfacts/understanding-drug-use-addiction\n",
    "   \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Substance Abuse and Mental Health Services Administration. (2021). Key substance use and mental health indicators in the United States: Results from the 2020 National Survey on Drug Use and Health. Center for Behavioral Health Statistics and Quality, Substance Abuse and Mental Health Services Administration. https://www.ncbi.nlm.nih.gov/books/NBK571451/\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Ryu, S., & Fan, L. (2022). The relationship between financial worries and psychological distress among U.S. adults. Journal of Family and Economic Issues, 44(1), 16–33. https://doi.org/10.1007/s10834-022-09820-9\n",
    "   \n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) Nagelhout, G. E., Hummel, K., de Goeij, M. C., de Vries, H., Kaner, E., & Lemmens, P. (2017). How economic recessions and unemployment affect illegal drug use: A systematic realist literature review. International Journal of Drug Policy, 44, 69–83. https://doi.org/10.1016/j.drugpo.2017.03.013"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis**: Higher county-level unemployment rates and lower per-capita personal income will be able to accurately predict increases in drug overdose mortality rates per 100,000 residents in California counties from 2010–2019. Furthermore, increases in unemployment will predict increases in overdose mortality rates with a lag of one to two years across California counties.\n",
    "<br>\n",
    "\n",
    "**Null Hypothesis**: County-level unemployment rates, per-capita personal income, and their lagged values are not significantly associated with drug overdose mortality rates in California counties from 2010–2019.\n",
    "<br>\n",
    "\n",
    "**Rationale**: Economic distress has been linked with increased substance use and overdose mortality due to reduced social security, financial strain, and decreased access to healthcare. The proxies we decided to look at include: Unemployment rate, which represents short-term economic shock, per-capita income, and regional economic activity, which both capture more long-term financial stress. Consequently, counties experiencing higher unemployment and lower income levels are more likely to exhibit higher rates of overdose mortality. Furthermore, economic shocks may not immediately translate into mortality, suggesting that there is a significant lag from when unemployment increases to a spike in drug overdose mortalities by one or more years. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview\n",
    "\n",
    "\n",
    "- **Dataset #1**\n",
    "  - Dataset Name: ***California Drug Overdose by County***\n",
    "  - Link to the dataset: https://github.com/COGS108/Group078_WI26/blob/master/County%20Drug%20Deaths.csv \n",
    "  - Number of observations: There are 1879 observations that represent the number of deaths labeled by ICD-10 based on the year and county. There is a total of 47 counties in California in this dataset. The time period of this dataset ranges from 2018-2023. \n",
    "  - Number of variables: There are around 10 key variables, including the county name, year, UCD, MCD, deaths, population, crude rate, total deaths by year, and crude rate by year. \n",
    "  - Variables most relevant to this project: \n",
    "    - County: tells us which county the data is for\n",
    "    - Year: the time period of the observation\n",
    "    - UCD/MCD: tells us how the observations died according to ICD-10 codes\n",
    "    - Crude Rate: the actual number or rate of deaths in that county, which is the main variable we’re analyzing\n",
    "    - Population: can be used to calculate per-capita rates or standardize data\n",
    "    - UCD/MCD: Provides a descriptions about the drug and cause of death. \n",
    "  - Dataset shortcomings:\n",
    "    - Some counties may have very few deaths in certain years, which can make the data noisy or misleading\n",
    "    - Smaller counties with low counts may have suppressed or missing values to protect privacy\n",
    "    - The dataset only tracks known reported drug overdose deaths\n",
    "    - Short yearly range may not capture short-term spikes\n",
    "    - MCD codes can be represented by UCD codes, giving us less information about how they died\n",
    "- **Dataset #2** \n",
    "  - Dataset Name: ***U.S. Bureau of Economic Analysis Regional GDP and Personal Income Dataset***\n",
    "  - Link to the dataset: https://apps.bea.gov/itable/?ReqID=70&step=1&_gl=1*1nng24c*_ga*MjEzMjM4MzUxOS4xNzI1OTg2NTUz*_ga_J4698JNNFT*MTc0MTM4ODkxMy40My4xLjE3NDEzOTEwMjQuNDYuMC4w#eyJhcHBpZCI6NzAsInN0ZXBzIjpbMSwyOSwyNSwzMSwyNiwyNywzMF0sImRhdGEiOltbIlRhYmxlSWQiLCIyMCJdLFsiTWFqb3JfQXJlYSIsIjQiXSxbIlN0YXRlIixbIjA2MDAwIl1dLFsiQXJlYSIsWyIwNjAwMCJdXSxbIlN0YXRpc3RpYyIsWyIzIl1dLFsiVW5pdF9vZl9tZWFzdXJlIiwiTGV2ZWxzIl0sWyJZZWFyIixbIi0xIl1dLFsiWWVhckJlZ2luIiwiLTEiXSxbIlllYXJfRW5kIiwiLTEiXV19 \n",
    "  - Number of observations: There are roughly 1,000–2,000 observations depending on which states and years are included. Each row represents a state or region for a specific year and economic measure.\n",
    "  - Number of variables: There are about 6-7 variables, including the county, the year, the type of statistic (GDP, personal income), the population size, and the economic value itself.\n",
    "  - Variables most relevant to this project\n",
    "    - State / Major Area: tells you which state or region the data is for\n",
    "    - Year: shows the time period for each observation\n",
    "    - Statistic: indicates whether the number is GDP, personal income, or another measure\n",
    "    - Value: the actual economic number in dollars, which is what we would use to analyze trends or make predictions\n",
    "  - Dataset shortcomings:\n",
    "    - Some years or regions might be missing data, especially older years or smaller areas\n",
    "    - The data is mostly aggregated, so it doesn’t show finer details within each state\n",
    "    - It only includes economic measures, so other factors like population or policy aren’t included\n",
    "    - The dataset is updated yearly, so it’s not great for predicting real-time changes\n",
    "- **Dataset #3** \n",
    "  - Dataset Name: ***Local Area Unemployment Statistics (LAUS), Seasonally Adjusted – California***\n",
    "  - Link to the dataset:  https://data.bls.gov/multi-screen?survey=la\n",
    "  - Number of observations: There are thousands of observations since the dataset tracks monthly unemployment for all counties in California over many years. Each row represents a county in a specific month and year.\n",
    "  - Number of variables: There are around 5–7 key variables, including the county, month, year, labor force size, number of unemployed people, and the unemployment rate.\n",
    "  - Variables most relevant to this project: \n",
    "    - County / Area: tells us which part of California the data refers to\n",
    "    - Year / Month: indicates the time period of the observation\n",
    "    - Labor Force / Unemployed: the actual numbers of people employed or unemployed\n",
    "    - Unemployment Rate: percentage of the labor force that is unemployed, which is often the main variable of interest for analysis\n",
    "  - Dataset shortcomings: \n",
    "    - Some smaller counties may have noisy data or missing values for certain months\n",
    "    - The dataset only tracks unemployment and labor force info, so it doesn’t include other economic factors like income or GDP\n",
    "    - Since the data is seasonally adjusted, it might hide short-term fluctuations\n",
    "    - Monthly data can be harder to merge with datasets that are only available annually\n",
    "- **Dataset Combination Plan**:\n",
    "  <br>To combine the three datasets, we will first standardize county names and years so they align across all sources. We will then merge the data by county and year, resulting in a dataset where each row represents one county in a specific year and includes the unemployment rate (LAUS), per-capita personal income and GDP (BEA), and drug overdose deaths (County Overdose dataset). Additionally, we will create derived variables, such as overdose rates per 100,000 residents, and lagged economic indicators to explore how changes in unemployment or income may predict future overdose mortality. This merged dataset will be used as the input for building a predictive model.\n",
    "  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/COGS108/Group078_WI26/master/data/00-raw/county_drug_deaths.csv', 'filename':'county_drug_deaths.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/COGS108/Group078_WI26/refs/heads/master/data/00-raw/BEA_econ_dataset.csv', 'filename':'BEA_econ_dataset.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/COGS108/Group078_WI26/refs/heads/master/data/00-raw/labour_stats_season_adjusted_dataset.csv', 'filename': 'labour_stats_season_adjusted_dataset.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/COGS108/Group078_WI26/refs/heads/master/data/00-raw/BLS_county_level_CA.csv', 'filename': 'BLS_county_level_CA.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/COGS108/Group078_WI26/master/data/00-raw/county_drug_deaths.csv', 'filename':'county_drug_deaths.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 California Drug Overdeath Deaths by County\n",
    "\n",
    "#### Dataset Description \n",
    "This dataset contains drug overdose mortality data for counties in California obtained from CDC WONDER. Each row represents the number of overdose deaths classified using **ICD-10 codes**. ICD-10 is an international alphanumeric classification system used to identify causes of death. This analysis focuses on substance-specific ICD-10 codes including T40.0–T40.5, T42.3–T42.4, and T43.6–T43.8, which correspond to commonly observed drugs such as opium, heroin, other opioids, synthetic opioids, cocaine, psychostimulants, and benzodiazepines.\n",
    "\n",
    "The dataset also includes broader poisoning intent codes with the columns *Underlying Cause of Death* and *Multiple Cause of Death* variables. Codes X40–X44 represent accidental drug poisoning, X60–X64 represent intentional self-poisoning, and Y10–Y14 represent poisoning of undetermined intent. The Underlying Cause of Death (UCD) identifies the primary cause initiating the fatal event, while the Multiple Cause of Death (MCD) provides additional contributing substances involved in the death.\n",
    "\n",
    "Geographic information is provided through the *County* and *County Code* variables, which identify the reporting county. These are captured by the Year and Year Code variables, which indicate the calendar year in which deaths occurred. CDC WONDER provided the reported death rates with the range of 2018 to 2023.\n",
    "\n",
    "Outcome measures include *Deaths* and *Population*, representing the number of recorded deaths and the county population for that year. The dataset also reports a *Crude Rate*, defined as the number of deaths per 100,000 population. When death counts are small (typically below 20), CDC WONDER labels the crude rate as “Unreliable,” indicating statistical instability in the rate estimate.\n",
    "\n",
    "#### Dataset Limitations\n",
    "One of the potential problems in this data set in this dataset would be the statistically small crude rates. Some crude rates are miniscule that they are labeled as \"Unreliable\". This can become a potential limitation for analysis when working with the crude rate data. Another problem is the short annual range of 2018 - 2023. This small range makes it difficult to measure drastic spikes in overdose death overtime. The UCD and MCD are redundant variables because the ICD-10 codes already help group the drugs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"data/00-raw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_drugs = pd.read_csv(\"data/00-raw/county_drug_deaths.csv\")\n",
    "data_drugs.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset is neatly formatted in a csv file type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drugs['County'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drugs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the dataset contains 1977 rows and 12 columns. There are 7 object datatypes and 5 integer datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drugs.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be null 98 entries. There are 1879 null entries in the notes section because the Notes columns contains additional information such as footnotes and caveats at the bottom of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drugs['Crude Rate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_drugs['Crude Rate'] == 'Unreliable').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the crude rates are labeled as unreliable. This will result in a skewed distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean this dataset, we will first drop the **Notes** column because it contains many null values. We will also drop **Year Code**, as it is redundant with the **Year** column. Next, we will remove any rows that contain only null values. We will convert numeric columns currently stored as floats to integer datatypes where appropriate, such as **Deaths** and **Population**. We will also generalize the **Underlying Cause of Death (UCD)** and **Multiple Cause of Death (MCD)** labels into broader categories to reduce sparsity and simplify analysis. \n",
    "\n",
    "To address the “Unreliable” entries in the **Crude Rate** column, we will recompute the crude rate manually using `Deaths / Population * 100,000` and convert the column to a float datatype. Finally, we will create two additional columns **Total Deaths by County and Year** and **Crude Rate by County and Year** to provide stable county-level aggregate metrics that give context for individual drug-specific deaths and allow for comparison across counties of different population sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy for Clean Data \n",
    "data_drugs_clean = data_drugs.copy()\n",
    "data_drugs_clean = data_drugs_clean.drop(columns=['Notes', 'Year Code', 'Underlying Cause of death', 'Multiple Cause of death'])\n",
    "data_drugs_clean = data_drugs_clean.dropna()\n",
    "\n",
    "data_drugs_clean[['Year','Population','Deaths', 'County Code']] = data_drugs_clean[['Year','Population','Deaths', 'County Code']].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drugs_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drugs_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drugs_clean['Underlying Cause of death Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drugs_clean['Multiple Cause of death Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ICD-10 codes with general labels \n",
    "\n",
    "mappings_UCD = {'X41': 'accidental', 'X42': 'accidental', 'X44': 'accidental', 'X64': 'intentional',\n",
    "                'X61': 'intentional', 'X62': 'intentional', 'X40': 'accidental', 'Y14': 'undetermined'}\n",
    "\n",
    "mappings_MCD = {'T40.1': 'Heroin', 'T40.2': 'Other opiods', 'T40.3': 'Methadone', 'T40.4': 'Synthetic opioids',\n",
    "                'T40.5': 'Cocaine', 'T42.4': 'Sedatives', 'T43.6': 'Psychostimulants', 'X40': 'Unspecified',\n",
    "                'X41': 'Unspecified', 'X42': 'Unspecified', 'X44': 'Unspecified', 'X61': 'Unspecified', \n",
    "                'X62': 'Unspecified', 'X64': 'Unspecified', 'Y14': 'Unspecified'}\n",
    "\n",
    "data_drugs_clean['Underlying Cause of death Code'] = data_drugs_clean['Underlying Cause of death Code'].map(mappings_UCD)\n",
    "data_drugs_clean['Multiple Cause of death Code'] = data_drugs_clean['Multiple Cause of death Code'].map(mappings_MCD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute crude weight to get rid of Unreliable \n",
    "data_drugs_clean['Crude Rate'] = data_drugs_clean['Deaths'] / data_drugs_clean['Population'] * 100000\n",
    "data_drugs_clean['Crude Rate'] = data_drugs_clean['Crude Rate'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total deaths per county-year\n",
    "data_drugs_clean['Total Deaths by County and Year'] = data_drugs_clean.groupby(['County','Year'])['Deaths'].transform('sum')\n",
    "\n",
    "# Compute crude rate for total by 100000\n",
    "data_drugs_clean['Crude Rate by County and Year'] = (data_drugs_clean['Total Deaths by County and Year'] / data_drugs_clean['Population'] * 100000).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drugs_clean.to_csv(\"data/02-processed/county_drug_deaths_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final clean version of the drug dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy for Clean Data \n",
    "data_drugs_clean = data_drugs.copy()\n",
    "data_drugs_clean = data_drugs_clean.drop(columns=['Notes', 'Year Code', 'Underlying Cause of death', 'Multiple Cause of death'])\n",
    "data_drugs_clean = data_drugs_clean.dropna()\n",
    "\n",
    "data_drugs_clean[['Year','Population','Deaths', 'County Code']] = data_drugs_clean[['Year','Population','Deaths', 'County Code']].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drugs_clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 U.S. Bureau of Economic Analysis Regional GDP and Personal Income Dataset\n",
    "\n",
    "#### Dataset Description:\n",
    "This dataset is obtained directly through The U.S. Bureau of Economic Analysis. The Gross personal income by county, county population size, and the per capita personal income values are obtained for all 58 counties in the state of California, across 15 years from 2010 to 2014.<br>\n",
    "The Dataset on it own is a good baseline for many of the downstream analysis we will run.\n",
    "#### Dataset Limitations:\n",
    "1. This dataset only includes county level income data, and have relatively low temporal resolution. i.e. only one mesurement per county is taken per year, instead of tracking the change in the income per captia over each month.\n",
    "\n",
    "2. In some area, particularly rural parts of California, the size of informal economy(where people trade without documenting or paying any tax) may be large. Thus, we have to take into consideration of the fact that this dataset may not 100% reflect the per capita income landscape across different counties in CA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dataset 2\n",
    "# Skip the first 3 rows which are metadata/legends\n",
    "df_CA_personal_income = pd.read_csv(\"data/00-raw/BEA_econ_dataset.csv\", on_bad_lines='skip', skiprows=3)\n",
    "\n",
    "# Quick Look at the Dataset\n",
    "print(\"Quick Look at the U.S. Bureau of Economic Analysis Regional GDP and Personal Income Dataset\")\n",
    "print(df_CA_personal_income.head())\n",
    "print(type(df_CA_personal_income))\n",
    "print(\"\\nDataFrame shape:\", df_CA_personal_income.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df_CA_personal_income.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure each row uses the same unit for measurment\n",
    "\n",
    "# Converting rows with unit (thousands of dollars) into the unit (dollars)\n",
    "# Filter rows where LineCode == 1.0 (Personal income rows)\n",
    "personal_income_rows = df_CA_personal_income['LineCode'] == 1.0\n",
    "\n",
    "# Multiply all year columns by 1000 for personal income rows\n",
    "year_columns = [col for col in df_CA_personal_income.columns if col.isdigit()]\n",
    "df_CA_personal_income.loc[personal_income_rows, year_columns] = df_CA_personal_income.loc[personal_income_rows, year_columns] * 1000\n",
    "\n",
    "# Update the description column for personal income rows\n",
    "df_CA_personal_income.loc[personal_income_rows, 'Description'] = 'Personal income (dollars)  '\n",
    "\n",
    "# Update Column name to keep consistency across datasets\n",
    "df_CA_personal_income = df_CA_personal_income.rename(columns={'GeoFIPS': 'County Code', 'GeoName': 'County'})\n",
    "\n",
    "# Update the Descriptions column title to keep consistency\n",
    "df_CA_personal_income[\"Description\"] = df_CA_personal_income['Description'].str[0:-2]\n",
    "\n",
    "# Verify the changes\n",
    "# print(\"Updated DataFrame (showing personal income rows):\")\n",
    "print(df_CA_personal_income.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the rows with NaN from the dataset\n",
    "# See where NaN values are\n",
    "print(df_CA_personal_income.isnull().sum())\n",
    "print(\"\\nRows with any NaN:\")\n",
    "print(df_CA_personal_income.isnull().any(axis=1).sum())\n",
    "\n",
    "# Remove rows with NaN\n",
    "df_CA_personal_income = df_CA_personal_income.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns and Rows in the dataset\n",
    "print(\"====Properties of the dataset====\")\n",
    "\n",
    "print(\"====Years====\")\n",
    "print(*year_columns)\n",
    "print(f\"Number of years included in the Dataset: {len(year_columns)}\")\n",
    "\n",
    "print(\"====County in California====\")\n",
    "county_list_raw = df_CA_personal_income[\"County\"].unique()\n",
    "county_list = []\n",
    "for i in range(len(county_list_raw)):\n",
    "    if \"CA\" in str(county_list_raw[i]):\n",
    "        county_list.append(county_list_raw[i])\n",
    "    else:\n",
    "        continue\n",
    "# print(df_CA_personal_income[\"GeoName\"].unique())\n",
    "print(county_list)\n",
    "print(f\"Number of counties included in the Dataset: {len(county_list)}\")\n",
    "\n",
    "print(\"====Economic Metrics Included====\")\n",
    "for metric in df_CA_personal_income[\"Description\"].unique():\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the basic data statistics\n",
    "# Breaking each variable into its own df\n",
    "df_county_personal_income = df_CA_personal_income[df_CA_personal_income[\"Description\"] == \"Personal income (dollars)\"]\n",
    "df_county_population = df_CA_personal_income[df_CA_personal_income[\"Description\"] == \"Population (persons)\"]\n",
    "df_county_per_cap_income = df_CA_personal_income[df_CA_personal_income[\"Description\"] == \"Per capita personal income (dollars)\"]\n",
    "\n",
    "print(df_county_personal_income.describe().iloc[1:4,:])\n",
    "print(df_county_population.describe().iloc[1:4,:])\n",
    "print(df_county_per_cap_income.describe().iloc[0:4,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at the general trend of each county's personal income per captia over time\n",
    "# Filter for per capita personal income rows\n",
    "per_capita_rows = df_CA_personal_income['Description'].str.contains('Per capita personal income')\n",
    "df_per_capita = df_CA_personal_income[per_capita_rows]\n",
    "\n",
    "# Set up the years for plotting\n",
    "years = [int(col) for col in year_columns]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each county's per capita income as a line\n",
    "for idx, row in df_per_capita.iterrows():\n",
    "    county = row['County']\n",
    "    values = row[year_columns].values.astype(float)\n",
    "    plt.plot(years, values, label=county)\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Per Capita Personal Income (dollars)')\n",
    "plt.title('County Per Capita Personal Income Over Time')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize='small', ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretation:\n",
    "From this plot along we have regonized a bimodal distribution of income per capita across different states. We should take this into account for our down-stream analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3 US Bureau of Labor Statistics dataset\n",
    "\n",
    "#### Dataset Description:\n",
    "This Dataset includes the following monthly labor statistics for all CA county (2010-2025)\n",
    "* Unemployment\n",
    "* Unempolyment Rate\n",
    "* Empolyment\n",
    "* Labor forcce\n",
    "\n",
    "#### Dataset Limitations:\n",
    "1. The data is not seasonally adjusted, thus we may need to perform certain preprocessing steps in the down-stream analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "\n",
    "# Converting the .xlsx file to .csv file\n",
    "# df_xlsx = pd.read_excel(\"BLS_county_CA.xlsx\")\n",
    "# df_xlsx.to_csv(\"BLS_county_CA.csv\", index=False)\n",
    "\n",
    "# Import the .csv file\n",
    "df_labor_data_CA = pd.read_csv(\"BLS_county_CA.csv\")\n",
    "print(df_labor_data_CA.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset column header\n",
    "# Grab the 3rd row (index 2) and set it as the column headers\n",
    "df_labor_data_CA.columns = df_labor_data_CA.iloc[2]\n",
    "\n",
    "# Slice the DataFrame to drop rows 0, 1, and 2, keeping only the actual data\n",
    "df_labor_data_CA = df_labor_data_CA.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "print(df_labor_data_CA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the rows of the dataset according to what is been measurement\n",
    "\n",
    "# Create a clean column for the FIPS code (grabbing the '06001' part)\n",
    "df_labor_data_CA['County Code'] = df_labor_data_CA['Series ID'].str[5:10]\n",
    "\n",
    "# Create a clean column to verify the metric (grabbing the '03' part)\n",
    "df_labor_data_CA['Measure_Code'] = df_labor_data_CA['Series ID'].str[-2:]\n",
    "\n",
    "# Create a clean column that describes what is been measured\n",
    "stats_type_mapping = {\n",
    "    \"03\" : \"Unempolyment Rate\",\n",
    "    \"04\" : \"Unemployment\",\n",
    "    \"05\" : \"Employment\",\n",
    "    \"06\" : \"Labor Force\"\n",
    "}\n",
    "df_labor_data_CA['Measurement_Type'] = df_labor_data_CA['Measure_Code'].map(stats_type_mapping)\n",
    "\n",
    "# Create a clean column that describes which county in CA was being measured\n",
    "ca_fips_to_name = {\n",
    "    '06001': 'Alameda',\n",
    "    '06003': 'Alpine',\n",
    "    '06005': 'Amador',\n",
    "    '06007': 'Butte',\n",
    "    '06009': 'Calaveras',\n",
    "    '06011': 'Colusa',\n",
    "    '06013': 'Contra Costa',\n",
    "    '06015': 'Del Norte',\n",
    "    '06017': 'El Dorado',\n",
    "    '06019': 'Fresno',\n",
    "    '06021': 'Glenn',\n",
    "    '06023': 'Humboldt',\n",
    "    '06025': 'Imperial',\n",
    "    '06027': 'Inyo',\n",
    "    '06029': 'Kern',\n",
    "    '06031': 'Kings',\n",
    "    '06033': 'Lake',\n",
    "    '06035': 'Lassen',\n",
    "    '06037': 'Los Angeles',\n",
    "    '06039': 'Madera',\n",
    "    '06041': 'Marin',\n",
    "    '06043': 'Mariposa',\n",
    "    '06045': 'Mendocino',\n",
    "    '06047': 'Merced',\n",
    "    '06049': 'Modoc',\n",
    "    '06051': 'Mono',\n",
    "    '06053': 'Monterey',\n",
    "    '06055': 'Napa',\n",
    "    '06057': 'Nevada',\n",
    "    '06059': 'Orange',\n",
    "    '06061': 'Placer',\n",
    "    '06063': 'Plumas',\n",
    "    '06065': 'Riverside',\n",
    "    '06067': 'Sacramento',\n",
    "    '06069': 'San Benito',\n",
    "    '06071': 'San Bernardino',\n",
    "    '06073': 'San Diego',\n",
    "    '06075': 'San Francisco',\n",
    "    '06077': 'San Joaquin',\n",
    "    '06079': 'San Luis Obispo',\n",
    "    '06081': 'San Mateo',\n",
    "    '06083': 'Santa Barbara',\n",
    "    '06085': 'Santa Clara',\n",
    "    '06087': 'Santa Cruz',\n",
    "    '06089': 'Shasta',\n",
    "    '06091': 'Sierra',\n",
    "    '06093': 'Siskiyou',\n",
    "    '06095': 'Solano',\n",
    "    '06097': 'Sonoma',\n",
    "    '06099': 'Stanislaus',\n",
    "    '06101': 'Sutter',\n",
    "    '06103': 'Tehama',\n",
    "    '06105': 'Trinity',\n",
    "    '06107': 'Tulare',\n",
    "    '06109': 'Tuolumne',\n",
    "    '06111': 'Ventura',\n",
    "    '06113': 'Yolo',\n",
    "    '06115': 'Yuba'\n",
    "}\n",
    "\n",
    "df_labor_data_CA['County'] = df_labor_data_CA['County Code'].map(ca_fips_to_name)\n",
    "\n",
    "# Rearrange Column Heads\n",
    "column_list = list(df_labor_data_CA.columns)\n",
    "new_order = column_list[-4:] + column_list[:-4]\n",
    "df_labor_data_CA = df_labor_data_CA[new_order]\n",
    "\n",
    "# Filter the dataframe to ONLY keep the Unemployment Rate rows\n",
    "# df_labor_data_CA = df_labor_data_CA[df_labor_data_CA['Local Area Unemployment Statistics'] == '03']\n",
    "# print(df_labor_data_CA.columns)\n",
    "print(df_labor_data_CA.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN elements in the dataset\n",
    "cols_with_na = df_labor_data_CA.columns[df_labor_data_CA.isnull().any()].tolist()\n",
    "\n",
    "print(\"Columns with missing data:\", cols_with_na)\n",
    "\n",
    "print(df_labor_data_CA['Oct\\n2025'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the row with NaN\n",
    "df_labor_data_CA_clean = df_labor_data_CA.drop(columns=['Oct\\n2025'])\n",
    "print(\"==== Clean US Bureau of Labor Statistics dataset (CA, by county) 2010-2025====\")\n",
    "print(df_labor_data_CA_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the unique counties and measurements included\n",
    "print(\"==== Counties Included ====\")\n",
    "print(df_labor_data_CA_clean[\"County\"].unique())\n",
    "print(f\"{len(df_labor_data_CA_clean['County'].unique())} counties included in this dataset\")\n",
    "print(\"==== Labor Force Statistics Included ====\")\n",
    "print(df_labor_data_CA_clean[\"Measurement_Type\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BELOW====(Backup Dataset/ May not be used/ For our own reference)====**\n",
    "### Dataset 4: Local Area Unemployment Statistics (LAUS), Seasonally Adjusted (provided by California Employment Development Department)\n",
    "\n",
    "#### Dataset Description:\n",
    "Seasonally adujusted Unemployment dataset by Metropolitan area\n",
    "\n",
    "#### Data limitation\n",
    "\n",
    "It is not on the county level, so doesn't really fit our research objective. However, could serve as a valuable reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the County level unemployment dataset\n",
    "df_CA_unemployment = pd.read_csv(\"data/00-raw/labour_stats_season_adjusted_dataset.csv\", on_bad_lines='skip')\n",
    "\n",
    "print(\"====Quick Look at the Data Frame Imported====\")\n",
    "print(df_CA_unemployment.head())\n",
    "print(f\"Size of the raw unemployment dataset: {df_CA_unemployment.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the columns full of NaN\n",
    "# See where NaN values are\n",
    "print(\"Columns NaN counts\")\n",
    "print(df_CA_unemployment.isnull().sum())\n",
    "print(\"\\nRows with any NaN:\")\n",
    "print(df_CA_unemployment.isnull().any(axis=0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns 11 and 12 and rows with NaN\n",
    "df_CA_unemployment_clean = df_CA_unemployment.drop(['Unnamed: 11', 'Unnamed: 12'], axis=1)\n",
    "df_CA_unemployment_clean = df_CA_unemployment_clean.dropna(axis=0)\n",
    "print(df_CA_unemployment_clean.columns)\n",
    "print(df_CA_unemployment_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethics & Privacy Project Abstract\n",
    "Based on our proposed question and data sets used, some ethical and privacy issues that may arise would be based on the privacy of those who are documented participating in drug abuse or have overdosed. Depending on the counties/locations we choose to study, certain biases may arise. Certain counties that are of higher economic status could result in economic data bias, which could alter how drug abuse data is documented (richer counties document fewer overdoses due to better access to medical support/rehab). Additionally, reporting bias could also be a factor, since not all drug abuse cases and overdoses are accurately represented. This is because many cases are not reported due to a lack of advanced healthcare, which is especially prevalent in rural or low-income counties with poor medical infrastructure, resulting in less accurate reports.  \n",
    "  <br>\n",
    "  There are important equity and privacy issues that could be problematic when analyzing data in relation to drug abuse and the economic state of a county. For instance, even though the datasets used are all publicly available and grouped by counties, there remains a risk of re-identification, particularly in counties that are sparsely populated and where overdose events are rare. In order to counter this issue, our group will ensure that the data is collected strictly at the county level, and if there are smaller counties represented, the data is aggregated with others. Additionally, correlating drug abuse with economically distressed communities may stigmatize and raise concerns within these communities. We will address these issues by making sure to use neutral and non-judgmental language and only focusing on causal claims. \n",
    "\n",
    "\n",
    "### A. Data Collection\n",
    "- [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "  <br>\n",
    "  \n",
    "  Most of the data used in our project will likely be information from the county level, which means individual consent may not be directly required. This includes variables such as unemployment rates, public health statistics, and other demographics. However, if any of our data sources involve surveys, interviews, or healthcare records that more explicitly identify individuals, we would take greater care to contact people so they can opt-in or opt-out as research participants that clearly understand how their data will be used. A failure in doing so would violate ethical norms or privacy, and we would also harm participants’ trust with us.\n",
    " <br>\n",
    "- [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "  <br> \n",
    "  \n",
    "  Based on our proposed question and data sets used, some ethical and privacy issues that may arise would be based on the privacy of those who are documented participating in drug abuse or have overdosed. Depending on the counties/locations we choose to study, certain biases may arise. Certain counties that are of higher economic status could result in economic data bias, which could alter how drug abuse data is documented (richer counties document fewer overdoses due to better access to medical support/rehab). Additionally, reporting bias could also be a factor, since not all drug abuse cases and overdoses are accurately represented. This is because many cases are not reported due to a lack of advanced healthcare, which is especially prevalent in rural or low-income counties with poor medical infrastructure, resulting in less accurate reports. \n",
    "  <br>\n",
    "\n",
    "- [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "  <br>\n",
    "  \n",
    "  There are important equity and privacy issues that could be problematic when analyzing data in relation to drug abuse and the economic state of a county. For instance, even though the datasets used are all publicly available and grouped by counties, there remains a risk of re-identification, particularly in counties that are sparsely populated and where overdose events are rare. In order to counter this issue, our group will ensure that the data is collected strictly at the county level, and if there are smaller counties represented, the data is aggregated with others. Additionally, correlating drug abuse with economically distressed communities may stigmatize and raise concerns within these communities. We will address these issues by making sure to use neutral and non-judgmental language and only focusing on causal claims.  \n",
    "  <br> \n",
    "- [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "  <br>\n",
    "  \n",
    "  Because we are working with county or state-level data, individual demographic disparities may be avoided. At the same time, failing to consider demographic patterns could allow biased model outcomes to go unnoticed. If demographic data is included for fairness testing, it would need to be handled carefully and ethically. We recognize that including protected group data introduces its own privacy and misuse risks, but excluding it entirely may prevent us from identifying unequal impacts. Acknowledging this tension is an important part of our ethical reflection.\n",
    "  <br>\n",
    "### B. Data Storage\n",
    "- [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "  <br>\n",
    "  \n",
    "  Although we are primarily using publicly available, aggregated county-level data, we still recognize the importance of responsible data storage. Even public datasets can cause harm if altered, mishandled, or combined in ways that increase sensitivity. The datasets we use would be stored on secure systems with limited access only to the team members directly involved in the project. If any dataset were to contain more granular information in the future, stronger protections such as encryption and access logging would be necessary. We acknowledge that weak data security practices could undermine trust and create preventable risks.\n",
    "  <br>\n",
    "- [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "  <br>\n",
    "  \n",
    "  Because our project uses aggregated public data and does not collect individual-level identifiers, there is no direct mechanism for individuals to request removal of personal information. However, we recognize that the original data sources we pull from may have their own policies regarding data removal or correction. If our research were to expand to include individual-level data in the future, we would need to establish a clear process allowing participants to withdraw their information. Even when not legally required, considering the right to be forgotten reflects respect for individual autonomy.\n",
    "  <br>\n",
    "- [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "  <br>\n",
    "  \n",
    "  Since the data used in this project is publicly available and has been for a while, long-term retention may not pose a significant privacy risk. However, we acknowledge that keeping data indefinitely without purpose can create unnecessary exposure. A reasonable retention plan would involve maintaining datasets only for the duration of the research and deleting local copies once analysis and documentation are complete. Even if the risk is minimal, having a clear retention plan demonstrates intentional and responsible data stewardship on our part.\n",
    "  <br>\n",
    "### C. Analysis\n",
    "- [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "  <br>\n",
    "  \n",
    "  We recognize that statistical analysis with our datasets alone cannot fully capture the lived experiences behind county-level drug abuse data. Our assumptions about economic decline and drug/substance use may overlook structural, cultural, or policy-related factors that contribute to these patterns. Without engagement from public health experts, policymakers, or even affected communities, we do risk potentially oversimplifying the issue. Even if direct engagement is not feasible for this project, we acknowledge that blind spots may exist in how we interpret and frame our findings.\n",
    "  <br>\n",
    "- [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "  <br>\n",
    "  \n",
    "  We are aware that our hypothesis itself could introduce confirmation bias, especially since prior research or other findings can suggest a relationship to exist between unemployment and drug use. There may also be omitted confounding variables, such as healthcare access, education levels, or local policy differences, that influence drug abuse rates independently of unemployment. Additionally, some counties may have very low reported overdose rates, leading to imbalanced data that could distort model performance. Failing to account for these factors could unintentionally reinforce stereotypes or overstate causal interpretations.\n",
    "  <br>\n",
    "- [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "  <br>\n",
    "  \n",
    "  We have a responsibility to present correlations carefully and avoid implying causation where it does not exist. Choices in visualization such as scaling, color schemes, or selective reporting of results in maps or graphs can subtly exaggerate relationships. We will be careful not to highlight only statistically significant findings while ignoring null results. Our main goal will aim to best highlight the data we’ve collected and cleaned with no other motives. Misrepresentation, even unintentionally, could contribute to public misunderstanding or policy misuse.\n",
    "  <br>\n",
    "- [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "  <br>\n",
    "  \n",
    "  Our analysis focuses on aggregated county-level data, so direct PII should not be present. However, we remain aware that combining multiple datasets can increase identifiability in smaller counties. We will avoid displaying small cell counts or granular breakdowns that could indirectly expose sensitive information. Even if the risk is minimal, protecting privacy remains a core ethical consideration.\n",
    "  <br>\n",
    "- [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "  <br>\n",
    "\n",
    "  To ensure accountability, our data cleaning steps, modeling decisions, and analytical assumptions will be clearly documented throughout the steps of our project. Without reproducibility, errors or biases could go unnoticed and uncorrected. Transparent documentation also allows others to read, critique or build upon our work responsibly. If issues are identified later, having an auditable process makes it possible to revise findings rather than defensively justify them.\n",
    "  <br>\n",
    "### D. Modeling\n",
    "- [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "  <br>\n",
    "\n",
    "  Since our overdose datasets are compiled at the state level, we are not working with individual demographic identifiers. However, state-level economic indicators and overdose rates may still reflect underlying inequalities. Variables such as unemployment could indirectly correlate with historically marginalized populations due to systemic disparities. Even if we are not explicitly modeling protected characteristics, we acknowledge that economic data can function as a proxy for broader social inequities. This means our model could unintentionally reinforce patterns that are rooted in structural inequality rather than individual behavior.\n",
    "  <br>\n",
    "- [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "  <br>\n",
    "  \n",
    "  Because our data is aggregated at the state level, we cannot directly test for fairness across individual demographic groups. This limits our ability to detect whether predictions would disproportionately affect certain racial, gender, or socioeconomic populations within a state. We recognize that this is a limitation of our dataset. While state-level modeling reduces individual privacy concerns, it also masks within-state disparities, which could hide unequal impacts.\n",
    "  <br>\n",
    "- [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "  <br>\n",
    "  \n",
    "  In our project, we are trying to predict state-level overdose rates using economic indicators like unemployment. How we measure model performance directly affects how we interpret our results. For example, if we only focus on overall accuracy or average error, the model might appear strong even if it does a poor job predicting overdose rates in states with the highest levels of economic distress. Since those states are central to our research question, it is important to consider whether our evaluation metric truly reflects meaningful predictive performance. We recognize that the metric we choose influences what the model prioritizes and how convincing our conclusions appear.\n",
    "  <br>\n",
    "- [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "  <br>\n",
    "  \n",
    "  If our model predicts higher overdose rates in certain states based on economic indicators, we should be able to clearly explain which variables contributed to that prediction. Since this topic involves public health and sensitive social issues, using an interpretable modeling approach is important. Overly complex models could reduce transparency and make it harder to communicate findings responsibly. We recognize that clarity and interpretability are especially important when findings could influence policy discussions.\n",
    "  <br>\n",
    "- [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "  <br>\n",
    "  \n",
    "  Our datasets are secondary sources from Kaggle, meaning we rely on how the data was originally collected and processed. We did not control the initial data collection methods, which may introduce unknown biases or inconsistencies across states. Additionally, because the data is collected at the state level, our data analysis cannot be interpreted at the individual or county level. We acknowledge that our model identifies correlations rather than causal mechanisms, and failure to clearly communicate these limitations could lead to overgeneralization or misuse of results.\n",
    "  <br>\n",
    "### E. Deployment\n",
    "- [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "  <br>\n",
    "  \n",
    "  Yes, we plan to continuously evaluate predictive performance based on appropriate statistical measures such as RMSE, MAE, and R2. Performance will also be assessed across subgroups such as county and income level to identify any potential disparities or bias with the model. We will monitor the concept drift by tracking changes in unemployment and drug abuse trends over time and make changes to it when data distributions shift significantly. \n",
    "  <br>\n",
    "- [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "  <br>\n",
    "  \n",
    "  We will establish a formal review process in which any concerns will be addressed and taken into account when creating our model. We are aware that drug abuse can be a very difficult topic in general, and we will ensure that if any concerns come up, we will edit the model to address this. For example, we could retrain the model to omit certain data if needed, or we could adjust variable weighting, and even remove problematic proxy variables. \n",
    "  <br>\n",
    "- [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "  <br>\n",
    "  \n",
    "  All models will be version-controlled so that the previously validated versions can be brought back quickly. If there is significant bias or harmful impacts, we will suspend outputs and replace them temporarily with descriptive statistical reporting. No fully automated decisions will be permitted, and human oversight will remain the only decision-making process. Consequently, this makes sure that the model can be safely paused or reverted while issues are investigated. \n",
    "  <br>\n",
    "- [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "  <br>\n",
    "  \n",
    "  There is a risk of discrimination and stigmatization during the application process because this project analyzes sensitive topics such as drug abuse and employment. However, to reduce the risj we plan to ensure that the model will only look at geographic level outputs and not individuals. By proactively identifying risks such as profiling and discriminatory use, we aim to ensure the model supports equitable public health rather than contributing to harm. \n",
    "  <br>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team Expectation 1 – Communication & Meetings**\n",
    "<br>Our group will maintain clear and consistent communication through a group text chat. It's expected that everyone should respond to texts within the same day (ideally within a few hours), unless they have communicated ahead of time that they will be unavailable(i.e., being sick). We will also use our scheduled discussion section time as collaborative work time and meet weekly on Mondays from 3–5 PM at Geisel library to review our invidudual progress and delegate tasks for the upcoming week. If a scheduling conflict comes up, the member will notify the group in advance. After each meeting, we will summarize what was discussed and clearly outline individual responsibilities and deadlines in the group chat so expectations remain transparent.\n",
    "<br>\n",
    "\n",
    "**Team Expectation 2 – Task Division, Contributions & Accountability**\n",
    "<br>All members will contribute equally in overall effort across the entire project, including topic selection, dataset research, coding (wrangling, visualization, and analysis), writing explanations, and editing. While tasks may be divided based on individual strengths to maximize efficiency, no one person will complete an entire section alone. We will assign tasks during weekly meetings, primarily through volunteering and discussion, while ensuring workload is balanced. All responsibilities and deadlines will be documented in the group chat so progress is visible to everyone. If someone is struggling with a task, they are expected to communicate this as soon as possible so the team can redistribute work or provide support.\n",
    "<br>\n",
    "\n",
    "**Team Expectation 3 – Tone, Respect & Decision-Making**\n",
    "<br>We agree to maintain a respectful, direct, and constructive tone when discussing ideas. We will use “I” statements when giving feedback (e.g., “I think this approach may not work because…”), and we will assume that all criticism is meant to improve the project. We will encourage everyone to share their opinions and ensure that quieter members have space to speak. For decisions, we will first aim for group discussion and consensus. If we cannot reach agreement in a reasonable time frame, we will use a majority vote. If further clarification is needed, we will talk with our TA.\n",
    "<br>\n",
    "\n",
    "**Team Expectation 4 – Handling Conflict & Problem Situations**\n",
    "<br>If a team member is not completing agreed-upon responsibilities, we will first address the issue directly and respectfully through written communication, clearly stating what needs to be completed and by when. We will offer assistance if needed. If there is no improvement after one week, we will follow course policy and notify the professor with specific details. Our goal is to address issues early and maintain steady progress throughout the quarter.\n",
    "<br>\n",
    "\n",
    "**Team Expectation 5 – Project Planning & Organization**\n",
    "<br>We will create and maintain a shared plan with deadlines for each section of the project and update it as needed throughout the quarter. Regular weekly meetings will allow us to track progress, identify challenges, and adjust our timeline if necessary. This plan will help ensure we stay on schedule and avoid last-minute work.\n",
    "<br>\n",
    "\n",
    "Throughout this project, we are committed to building a collaborative, organized, and supportive team environment where everyone contributes equally and communicates openly. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/2  |  3-5 PM | Pick 2 potential datasets each & evaluate each dataset baded on the variables and research potential  | Finalize our datasets and research question & outline and split up the proposal sections | \n",
    "| 2/4  |  5-7 PM |  Finish all the sections in the proposal based on how we divied up the workload  | Review and edit all the sections for the proposal and submit | \n",
    "| 2/9  | 3-5 PM  | Import the selected datasets, handle missing values and obvious data issues, and create summary statistics for the dataset  | Split up the project proposal feedback and make revisions on the Data Checkpoint file, determine what comparisons or relationships we will explore within our chosen datasets  |\n",
    "| 2/17  | 5-7 PM  | Finish the review sections that were assigned per ech group member and push edits to the main | Refine the research question based on project proposal feedback, complete the dataset analysis and turn in our Data Checkpoint   |\n",
    "| 2/23  | 3-5 PM  | Run selected statistical models and test, record the outputs and interpretations of the data | Review the results of the data collectively, troubleshoot unexpected findings, and confirm our analysis aligns with our research question |\n",
    "| 3/2  | 3-5 PM  | Rerun the finalized models and clean up our code, and write clear interpretations of the results for our report | Create data visualizations, split up sections of the EDA checkpoint for each group member to work on, and verify that all our conclusions made are supported by our statistical analysis |\n",
    "| 3/4  | 5-7 PM  | Finish all the sections of our EDA Checkpoint | Review and clean up code, submit our EDA Checkpoint assignment |\n",
    "| 3/9  | 3-5 PM  | Do a full code review for clarity and correctness, and double-check all calculations and outputs for the data | Finalize our presentation slides, ensure that each member is prepared to explain our projectand record our project video |\n",
    "| 3/16  | 3-5 PM  | Cross-check our project with all the rubric requirements and make final edits to our project | Turn in the Final Project & complete the Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:COGS108_FA25]",
   "language": "python",
   "name": "conda-env-COGS108_FA25-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
